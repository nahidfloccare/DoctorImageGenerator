"""
Doctor Image Generator - Python API
Main interface for generating photorealistic doctor images using FLUX + PuLID
Updated to use Doctor.json workflow
"""

import os
import json
import time
import uuid
import yaml
from pathlib import Path
from typing import Dict, Optional, Union, List
import websocket
import urllib.request
import urllib.parse

from prompts.templates import build_prompt, get_scenario_list, SCENARIOS


class DoctorImageGenerator:
    """
    Main class for generating doctor images using ComfyUI backend
    Uses Doctor.json workflow with FLUX-Krea + PuLID + FaceDetailer
    """
    
    def __init__(self, 
                 comfyui_url: str = "http://127.0.0.1:8188",
                 config_path: str = "config.yaml"):
        """
        Initialize the generator
        
        Args:
            comfyui_url: URL where ComfyUI server is running
            config_path: Path to configuration file
        """
        self.comfyui_url = comfyui_url
        self.config = self._load_config(config_path)
        self.client_id = str(uuid.uuid4())
        
        # Paths
        self.inputs_dir = Path(self.config["paths"]["inputs"])
        self.outputs_dir = Path(self.config["paths"]["outputs"])
        self.workflows_dir = Path(self.config["paths"]["workflows"])
        
        # Create directories if they don't exist
        self.inputs_dir.mkdir(exist_ok=True, parents=True)
        self.outputs_dir.mkdir(exist_ok=True, parents=True)
        
    def _load_config(self, config_path: str) -> dict:
        """Load configuration from YAML file"""
        if not os.path.exists(config_path):
            raise FileNotFoundError(f"Config file not found: {config_path}")
        
        with open(config_path, 'r') as f:
            return yaml.safe_load(f)
    
    def _queue_prompt(self, prompt: dict) -> str:
        """Queue a prompt to ComfyUI server"""
        p = {"prompt": prompt, "client_id": self.client_id}
        data = json.dumps(p).encode('utf-8')
        req = urllib.request.Request(f"{self.comfyui_url}/prompt", data=data)
        req.add_header('Content-Type', 'application/json')
        
        try:
            with urllib.request.urlopen(req) as response:
                result = json.loads(response.read())
                return result['prompt_id']
        except urllib.error.HTTPError as e:
            error_body = e.read().decode() if hasattr(e, 'read') else str(e)
            try:
                error_json = json.loads(error_body)
                print(f"\n‚ùå ComfyUI Error:")
                print(json.dumps(error_json, indent=2))
            except:
                print(f"\n‚ùå Error: {error_body}")
            raise RuntimeError(f"Failed to queue prompt: {e}")
    
    def _get_image(self, filename: str, subfolder: str = "", folder_type: str = "output") -> bytes:
        """Get generated image from ComfyUI"""
        data = {"filename": filename, "subfolder": subfolder, "type": folder_type}
        url_values = urllib.parse.urlencode(data)
        
        try:
            with urllib.request.urlopen(f"{self.comfyui_url}/view?{url_values}") as response:
                return response.read()
        except Exception as e:
            raise RuntimeError(f"Failed to get image: {e}")
    
    def _get_history(self, prompt_id: str) -> dict:
        """Get history for a specific prompt"""
        try:
            with urllib.request.urlopen(f"{self.comfyui_url}/history/{prompt_id}") as response:
                return json.loads(response.read())
        except Exception as e:
            raise RuntimeError(f"Failed to get history: {e}")
    
    def _wait_for_completion(self, prompt_id: str, timeout: int = 600) -> dict:
        """Wait for prompt to complete and return results"""
        start_time = time.time()
        
        while time.time() - start_time < timeout:
            history = self._get_history(prompt_id)
            
            if prompt_id in history:
                return history[prompt_id]
            
            time.sleep(1)
        
        raise TimeoutError(f"Image generation timed out after {timeout} seconds")
    
    def _load_workflow(self, workflow_name: str = None) -> dict:
        """Load ComfyUI workflow JSON - Uses Doctor.json by default"""
        if workflow_name is None:
            workflow_name = self.config.get("workflow", {}).get("default", "Doctor.json")
        
        workflow_path = self.workflows_dir / workflow_name
        
        if not workflow_path.exists():
            # Try ComfyUI directory as fallback
            workflow_path = Path("ComfyUI") / workflow_name
            if not workflow_path.exists():
                raise FileNotFoundError(
                    f"Workflow not found: {workflow_name}\n"
                    "Please ensure Doctor.json is in the workflows directory."
                )
        
        print(f"üîç Loading workflow: {workflow_path}")
        
        with open(workflow_path, 'r') as f:
            return json.load(f)
    
    def _update_workflow(self, 
                        workflow: dict, 
                        doctor_image_path: str,
                        positive_prompt: str,
                        negative_prompt: str,
                        additional_images: List[str] = None) -> dict:
        """
        Update Doctor.json workflow with specific parameters
        
        Workflow structure:
        - Node 76: CheckpointLoaderSimple (flux1-krea-dev.safetensors)
        - Node 23: PulidFluxModelLoader (pulid_flux_v0.9.1.safetensors)
        - Node 6: CLIPTextEncode (positive prompt)
        - Node 7: CLIPTextEncode (negative prompt)
        - Node 77: FluxGuidance (2.5)
        - Node 11, 27, 28: LoadImage (reference images)
        - Node 3: KSampler (main generation, denoise=1.0, scheduler=beta)
        - Node 36: FaceDetailer (hands, denoise=0.25)
        - Node 73: FaceDetailer (face, denoise=0.15)
        - Node 38: KSampler (refinement, denoise=0.35)
        """
        import random
        import shutil
        
        model_settings = self.config.get("model_settings", {})
        detail_config = self.config.get("detail_enhancement", {})
        pulid_config = self.config.get("pulid", {})
        
        for node_id, node in workflow.items():
            node_type = node.get("class_type", "")
            
            # Checkpoint Loader - Use flux1-krea-dev
            if node_type == "CheckpointLoaderSimple":
                node["inputs"]["ckpt_name"] = model_settings.get("flux_model", "flux1-krea-dev.safetensors")
                print(f"   ‚úì Checkpoint: {node['inputs']['ckpt_name']}")
            
            # CLIP Loaders
            elif node_type == "DualCLIPLoader":
                node["inputs"]["clip_name1"] = "t5xxl_fp16.safetensors"
                node["inputs"]["clip_name2"] = "clip_l.safetensors"
                node["inputs"]["type"] = "flux"
            
            # VAE Loader
            elif node_type == "VAELoader":
                node["inputs"]["vae_name"] = "ae.safetensors"
            
            # PuLID Model Loader
            elif node_type == "PulidFluxModelLoader":
                node["inputs"]["pulid_file"] = pulid_config.get("model", "pulid_flux_v0.9.1.safetensors")
                print(f"   ‚úì PuLID: {node['inputs']['pulid_file']}")
            
            # Apply PuLID
            elif node_type == "ApplyPulidFlux":
                node["inputs"]["weight"] = pulid_config.get("weight", 1.0)
                node["inputs"]["start_at"] = pulid_config.get("start_at", 0.0)
                node["inputs"]["end_at"] = pulid_config.get("end_at", 1.0)
            
            # Positive Prompt (Node 6)
            elif node_type == "CLIPTextEncode" and node_id == "6":
                node["inputs"]["text"] = positive_prompt
                print(f"   ‚úì Positive prompt: {positive_prompt[:60]}...")
            
            # Negative Prompt (Node 7)
            elif node_type == "CLIPTextEncode" and node_id == "7":
                node["inputs"]["text"] = negative_prompt
                print(f"   ‚úì Negative prompt: {negative_prompt[:60] if negative_prompt else '(empty)'}")
            
            # FluxGuidance (Node 77)
            elif node_type == "FluxGuidance":
                node["inputs"]["guidance"] = model_settings.get("guidance", 2.5)
                print(f"   ‚úì Guidance: {node['inputs']['guidance']}")
            
            # Load reference images (Nodes 11, 27, 28)
            elif node_type == "LoadImage":
                # Copy primary image to ComfyUI input
                filename = os.path.basename(doctor_image_path)
                comfyui_input = Path("ComfyUI/input") / filename
                comfyui_input.parent.mkdir(exist_ok=True, parents=True)
                shutil.copy2(doctor_image_path, comfyui_input)
                node["inputs"]["image"] = filename
                print(f"   ‚úì Reference image: {filename}")
            
            # Main KSampler (Node 3) - denoise=1.0
            elif node_type == "KSampler" and node_id == "3":
                node["inputs"]["steps"] = model_settings.get("steps", 100)
                node["inputs"]["cfg"] = model_settings.get("cfg_scale", 1.0)
                node["inputs"]["sampler_name"] = model_settings.get("sampler", "euler")
                node["inputs"]["scheduler"] = model_settings.get("scheduler", "beta")
                node["inputs"]["denoise"] = 1.0
                node["inputs"]["seed"] = random.randint(100000, 999999999999)
                print(f"   ‚úì Main KSampler: {node['inputs']['steps']} steps, {node['inputs']['scheduler']} scheduler")
            
            # Refinement KSampler (Node 38) - denoise=0.35
            elif node_type == "KSampler" and node_id == "38":
                node["inputs"]["steps"] = model_settings.get("steps", 100)
                node["inputs"]["cfg"] = model_settings.get("cfg_scale", 1.0)
                node["inputs"]["sampler_name"] = model_settings.get("sampler", "euler")
                node["inputs"]["scheduler"] = model_settings.get("scheduler", "beta")
                node["inputs"]["denoise"] = detail_config.get("final_denoise", 0.35)
                node["inputs"]["seed"] = random.randint(100000, 999999999999)
                print(f"   ‚úì Refinement KSampler: denoise={node['inputs']['denoise']}")
            
            # Hand FaceDetailer (Node 36)
            elif node_type == "FaceDetailer" and node_id == "36":
                node["inputs"]["seed"] = random.randint(100000, 999999999999)
                node["inputs"]["steps"] = detail_config.get("hand_refinement_steps", 100)
                node["inputs"]["cfg"] = 1.0
                node["inputs"]["sampler_name"] = "euler"
                node["inputs"]["scheduler"] = "simple"
                node["inputs"]["denoise"] = detail_config.get("hand_refinement_denoise", 0.25)
                node["inputs"]["guide_size"] = detail_config.get("hand_guide_size", 1024)
                print(f"   ‚úì Hand FaceDetailer: denoise={node['inputs']['denoise']}")
            
            # Face FaceDetailer (Node 73)
            elif node_type == "FaceDetailer" and node_id == "73":
                node["inputs"]["seed"] = random.randint(100000, 999999999999)
                node["inputs"]["steps"] = detail_config.get("face_refinement_steps", 100)
                node["inputs"]["cfg"] = 1.0
                node["inputs"]["sampler_name"] = "euler"
                node["inputs"]["scheduler"] = "simple"
                node["inputs"]["denoise"] = detail_config.get("face_refinement_denoise", 0.15)
                node["inputs"]["guide_size"] = detail_config.get("face_guide_size", 1024)
                print(f"   ‚úì Face FaceDetailer: denoise={node['inputs']['denoise']}")
            
            # Empty Latent Image
            elif node_type == "EmptyLatentImage":
                node["inputs"]["width"] = self.config.get("image_settings", {}).get("width", 1024)
                node["inputs"]["height"] = self.config.get("image_settings", {}).get("height", 1024)
                node["inputs"]["batch_size"] = 1
            
            # Upscale settings
            elif node_type == "ImageScaleBy":
                node["inputs"]["upscale_method"] = self.config.get("upscale", {}).get("method", "bicubic")
                node["inputs"]["scale_by"] = self.config.get("upscale", {}).get("scale", 1.5)
        
        return workflow
    
    def generate(self,
                 doctor_image_path: str,
                 scenario: str = "consultant",
                 photography_style: str = "professional",
                 custom_prompt: str = "",
                 custom_negative_prompt: Optional[str] = None,
                 output_filename: Optional[str] = None) -> Dict[str, Union[str, dict]]:
        """
        Generate a doctor image using Doctor.json workflow
        
        Args:
            doctor_image_path: Path to the doctor's headshot photo
            scenario: Scenario to generate (see prompts/templates.py for options)
            photography_style: Photography style (professional, cinematic, etc.)
            custom_prompt: Custom prompt (overrides scenario if provided)
            custom_negative_prompt: Custom negative prompt
            output_filename: Custom output filename (auto-generated if None)
        
        Returns:
            Dict containing:
                - output_path: Path to generated image
                - prompt_id: ComfyUI prompt ID
                - scenario: Used scenario
                - metadata: Generation metadata
        """
        # Validate inputs
        if not os.path.exists(doctor_image_path):
            raise FileNotFoundError(f"Doctor image not found: {doctor_image_path}")
        
        print(f"\n{'='*60}")
        print(f"üè• Doctor Image Generator")
        print(f"{'='*60}")
        print(f"üì∏ Reference image: {doctor_image_path}")
        
        # Build prompts
        if custom_prompt:
            # Use custom prompt directly with identity preservation prefix
            positive_prompt = f"Transform the person in the image: {custom_prompt}. Maintain the person's face and identity. Close-up shot, professional medical photography, 8k resolution, photorealistic, highly detailed natural skin texture, shot on Sony A7R IV, 85mm lens, f/1.8, cinematic lighting, volumetric lighting, raw photo, uncompressed."
            print(f"üìù Using custom prompt")
        else:
            # Build from scenario template
            if scenario not in SCENARIOS:
                raise ValueError(f"Unknown scenario: {scenario}. Available: {list(SCENARIOS.keys())}")
            
            positive_prompt, _ = build_prompt(
                scenario=scenario,
                photography_style=photography_style,
                custom_additions=""
            )
            # Add identity preservation prefix
            positive_prompt = f"Transform the person in the image: {positive_prompt}. Maintain the person's face and identity."
            print(f"üé¨ Scenario: {SCENARIOS[scenario]['name']}")
        
        # Use empty negative prompt like Doctor.json
        negative_prompt = custom_negative_prompt if custom_negative_prompt else ""
        
        print(f"\n‚öôÔ∏è Loading Doctor.json workflow...")
        workflow = self._load_workflow("Doctor.json")
        
        print(f"\nüîß Configuring workflow:")
        workflow = self._update_workflow(
            workflow=workflow,
            doctor_image_path=doctor_image_path,
            positive_prompt=positive_prompt,
            negative_prompt=negative_prompt
        )
        
        # Queue prompt
        print(f"\nüöÄ Queuing generation...")
        prompt_id = self._queue_prompt(workflow)
        print(f"üìã Prompt ID: {prompt_id}")
        
        # Wait for completion
        print(f"‚è≥ Generating image (estimated 3-5 minutes)...")
        history = self._wait_for_completion(prompt_id, timeout=600)
        
        # Get output images
        outputs = history.get("outputs", {})
        images = []
        
        for node_id, node_output in outputs.items():
            if "images" in node_output:
                for image in node_output["images"]:
                    images.append(image)
        
        if not images:
            raise RuntimeError("No images were generated")
        
        # Save the first image
        image_data = self._get_image(
            filename=images[0]["filename"],
            subfolder=images[0].get("subfolder", ""),
            folder_type=images[0].get("type", "output")
        )
        
        # Generate output filename
        if output_filename is None:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_filename = f"doctor_{scenario}_{timestamp}.png"
        
        output_path = self.outputs_dir / output_filename
        
        # Write image
        with open(output_path, 'wb') as f:
            f.write(image_data)
        
        print(f"\n‚úÖ Image generated successfully!")
        print(f"üìÅ Saved to: {output_path}")
        print(f"{'='*60}\n")
        
        # Return metadata
        return {
            "status": "success",
            "output_path": str(output_path),
            "prompt_id": prompt_id,
            "scenario": scenario,
            "metadata": {
                "doctor_image": doctor_image_path,
                "scenario_name": SCENARIOS.get(scenario, {}).get("name", "Custom"),
                "photography_style": photography_style,
                "positive_prompt": positive_prompt,
                "negative_prompt": negative_prompt,
                "custom_prompt": custom_prompt,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                "workflow": "Doctor.json"
            }
        }
    
    def list_scenarios(self) -> List[dict]:
        """List all available scenarios"""
        return get_scenario_list()
    
    def batch_generate(self,
                      doctor_image_path: str,
                      scenarios: List[str],
                      **kwargs) -> List[Dict]:
        """
        Generate multiple images with different scenarios
        
        Args:
            doctor_image_path: Path to doctor's headshot
            scenarios: List of scenario keys
            **kwargs: Additional arguments passed to generate()
        
        Returns:
            List of generation results
        """
        results = []
        
        for i, scenario in enumerate(scenarios, 1):
            print(f"\n{'='*60}")
            print(f"Generating {i}/{len(scenarios)}: {scenario}")
            print(f"{'='*60}")
            
            try:
                result = self.generate(
                    doctor_image_path=doctor_image_path,
                    scenario=scenario,
                    **kwargs
                )
                results.append(result)
            except Exception as e:
                print(f"‚ùå Error generating {scenario}: {e}")
                results.append({"error": str(e), "scenario": scenario})
        
        return results


# CLI-style usage example
if __name__ == "__main__":
    # Example usage
    generator = DoctorImageGenerator()
    
    # List available scenarios
    print("Available Scenarios:")
    print("=" * 60)
    for scenario in generator.list_scenarios():
        print(f"{scenario['key']:20} - {scenario['name']}")
